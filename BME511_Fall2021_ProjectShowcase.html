<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">


  <link rel="stylesheet" type="text/css" href="static/css/main.css">
  <!-- Requesting google and other search engine to not index these pages -->
  <meta name="robots" content="noindex">

  <!-- Favicon issues -->
  <link rel="apple-touch-icon" sizes="180x180" href="/ico/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="31x31" href="static/ico/favicon-31x31.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/ico/favicon-16x16.png">
  <link rel="manifest" href="static/ico/site.webmanifest">

  <title>Biomedical Signal Processing</title>
</head>

<body>
  <!-- Navigation -->
  <nav class="navbar navbar-expand-md navbar-light bg-light sticky-top">
    <div class="container">

      <a class="navbar-brand" href="#">
        <img src="static/images/BME511logo.png" width="48" alt="BME 511">
        Biomedical Signal Processing
      </a>

      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="true" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ms-auto">
          <li class="nav-item active">
            <a class="nav-link" href="#">Home
                  <span class="sr-only">(current)</span>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/haribharadwaj/syllabi/blob/main/PurdueBME511_BiomedSigProc.md" target="_blank">Syllabus</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/haribharadwaj/syllabi/blob/main/BME511_FinalProjectProposalGuidelines.md" target="_blank">ProjectSpecs</a>
          </li>
        </ul>
      </div>

    </div>
  </nav>
  <img src="static/images/PurdueGateway.jpg" class="img-fluid" alt="Welcome !">

  <!-- Page Content -->
  <main role="main" class="container">
  <h1 class="mt-4">Final Project Showcase</h1>
  <p>  Welcome to the <strong>Final Project Showcase</strong> page for the Fall 2021 edition of <strong>BME 511 Biomedical Signal Processing</strong>, at the <a href="http://engineering.purdue.edu/BME"> Weldon School of Biomedical Engineering </a> at <a href="http://www.purdue.edu/"> Purdue University</a>. BME 511 is a biomedical "data-science" course covering the application of signal processing and stochastic methods to biomedical signals and systems. While orientation to biomedical data is key to this course, the tools and concepts covered provide foundational skills that are useful in many domains. This course is distinct from other classic offerings in ECE/MA/STAT in at least three ways:
  <ol>
      <li> Relevant theory in signal processing and statistical methods is covered as needed, but a major focus is on implementation/application of the fundamental techniques to real-world biomedical signals. </li>
      <li> Statistical methods that are typically taught with a "univariate" perspective are expanded to topologically organized high-dimensional data such as time-series and images, and done so motivated by the needs in biomedical applications (e.g., electrophysiology, neuroimaging). </li>
      <li> This course uses practical applications to integrate probabilistic methods (e.g., estimation, detection, filtering) with classic linear-algebraic tools (e.g., Fourier/wavelet transforms, PCA, noise cancellation/regression). These foundational areas are often introduced in separate courses, but are powerful when brought together.</li>
  </ol>
  A "hands-on" approach is taken throughout the course via application-oriented problem sets. The course also includes a pre-defined <a href="https://nbviewer.org/github/haribharadwaj/notebooks/blob/main/BME511/MidtermProject.ipynb" target="_blank">midterm project (brain-computer interface)</a>, and a self-selected final project (last 5 weeks). An important goal of the final project is that each student should gain <i>independent</i> experience applying the tools/concepts to a real-world application of their interest. For more information about the overall course, please see the <a href="https://github.com/haribharadwaj/syllabi/blob/main/PurdueBME511_BiomedSigProc.md" target="_blank">syllabus</a>.  For more details about the project, please see the <a href="https://github.com/haribharadwaj/syllabi/blob/main/BME511_FinalProjectProposalGuidelines.md" target="_blank">project proposal specifications.</a> Student final projects are showcased below with their permission.
  </p>

  <h2 class="mt-4">List of projects in no particular order <span class="text-muted">(Click each to expand)</span></h2>
  <div class="accordion" id="accordionExample">

  <div class="accordion-item">
  <h2 class="accordion-header" id="heading3">
    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3" aria-expanded="true" aria-controls="collapse3">
      <h6>1. A non-invasive method for evaluating olfactory bulb dysfunction: proof-of-concept for Parkinson’s Disease diagnostics,
      <span class="text-muted ml-2">by Jessica Baer</span>
      </h6>
    </button>
  </h2>
  <div id="collapse3" class="accordion-collapse collapse" aria-labelledby="heading3" data-bs-parent="#accordionExample">
    <div class="accordion-body">
        <strong>Abstract: </strong> Parkinson’s Disease affects nearly every part of the body as this neurodegenerative disease causes neurons producing the neurotransmitter dopamine to gradually die off, reducing communication levels within the brain. Early, noninvasive diagnostic methods for Parkinson’s Disease (PD) are needed to better manage symptoms and potentially slow disease progression long-term. A recent study by Iravani et al. (2021) shows the potential for using noninvasive electrodes to monitor the common early symptom of olfactory bulb dysfunction and potentially diagnose PD earlier than current PD diagnostic methods that rely on motor symptoms. The objectives of this final project are to confirm the results of this study by identifying features in the electrode recordings that accurately distinguish between PD patients and healthy controls, developing a logistic regression model that uses these features to differentiate between PD patients and healthy controls with reasonable accuracy, and evaluate the correlation between the identified features and disease progression descriptors. To achieve these aims, a total of six key features were isolated from spectrogram representations of the electrode recordings and logistic and linear regression models were fit to the features and the various outcomes. Logistic models using various combinations of features were able to classify the subjects as PD patients and controls with ~95% accuracy. Key features also appeared to be correlated with the three disease progression descriptors that were evaluated.
        <div class="collapse d-flex justify-content-between mt-4">
          <a href="https://www.dropbox.com/s/zjs0lmycmctphla/A%20non-invasive%20method%20for%20evaluating%20olfactory%20bulb%20dysfunction_Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
            Slides
          </a>
          <a href="https://www.dropbox.com/s/t3idhzl4h4a0mpj/A%20non-invasive%20method%20for%20evaluating%20olfactory%20bulb%20dysfunction_Transcript.pdf?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
            Transcript
          </a>
        </div>
    </div>
    </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading2">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2" aria-expanded="true" aria-controls="collapse2">
        <h6>2. Prediction of Epileptic Seizures by Spike Extraction and Rate Comparison between Interictal and Preictal States,
        <span class="text-muted ml-2">by Katherine Foote</span>
        </h6>
      </button>
    </h2>
    <div id="collapse2" class="accordion-collapse collapse" aria-labelledby="heading2" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> Epilepsy, estimated to affect over 50 million people worldwide, is characterized by seizures which occur with little to no advanced external warning. Epilepsy diagnosis from an EEG is generally done by experts by identifying epileptiform discharges, generally characterized as spikes, sharp waves, and other spike-wave type forms. Early detection of an imminent seizure could allow a patient to be in a safe location or possibly take fast-acting seizure preventing medicines, and thus improve their quality of life. Multiple studies have shown that these waveforms are present in increasing quantity during the time leading up to the seizure. This project develops a process to automatically extract spikes and sharp waves in interictal EEG recordings and preictal EEG recordings and count the number of occurrences, generating a smoothed spike rate per observation period. The maximum rate during interictal periods will be calculated and this will be used as a threshold. Other EEG recordings will be processed similarly and compared to the rate of the threshold (per channel). If the EEG recording has a higher rate than the threshold, it indicates that a seizure is imminent. Using this method on a dataset from a Kaggle epilepsy detection competition, the accuracy of prediction for the test subject is above 78%.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/g6fnmf579f8vhbq/FinalPresentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/eqm58oivn2s1goz/video1001558539.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading1">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1" aria-expanded="true" aria-controls="collapse1">
        <h6>3. Gait Phase Classification and Prediction,
        <span class="text-muted"> by Tewbesta Alemayehu </span>
        </h6>
      </button>
      
    </h2>
    <div id="collapse1" class="accordion-collapse collapse" aria-labelledby="heading1" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Gait is the manner of walking or the analysis of each step when walking. It can be used to determine if the person has abnormalities in their walking and it is important in analyzing how a person should walk if they are missing a limb. There are different phases in gait. These are separated based on time of occurrence. Each gait cycle includes two periods which are stance and swing phase. Stance phase accounts for 60% of the total time for one step and is when both feet are on the ground. Swing phase, accounts for 40% of the total step time and is when the feet is in midair. Stance phase of gait is divided into loading response, midstance, terminal stance, and pre-swing. Swing phase is divided into initial swing, mid-swing, and terminal swing. It is rare to find gait data that has classified each gait phase, although it’s important in understanding the muscular condition of a patient. In this project, one of the objectives was to preprocess EMG data by smoothing it then labelling it the corresponding gait phase associated with it. The second objective was to make predictions of how a person should walk on the other foot given the manner of walking on the right foot. The results show that a good classification was made, and the prediction had a Mean Squared Error of 25.25 and r2 score of 0.29 on a small dataset of one subject walking for less than 40 second.

          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/wglo61r509oc8n4/BME%20Final%20Project%20Presentation%20Slide%20.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a> 
            <a href="https://www.dropbox.com/s/cdoguc2zgu244gs/BME%20Final%20Project%20Presentation%20Slide%20.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading4">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse4" aria-expanded="true" aria-controls="collapse4">
        <h6>4. Detection of Pulse peaks from wrist Photoplethysmography (PPG) signal using simultaneous chest Electrocardiogram (ECG) signal as ground truth,
        <span class="text-muted ml-2">by Sarwat Amin</span>
        </h6>
      </button>
    </h2>
    <div id="collapse4" class="accordion-collapse collapse" aria-labelledby="heading4" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> PPG systems can be conveniently built-in wrist watches and rings making it increasingly popular for different applications like heart rate estimation, respiratory rate, and blood pressure estimation. In case of respiratory estimation, it is necessary to detect the pulse peaks within the PPG signal to observe Respiratory Sinus Arrythmia (increase of heart rate during inhalation and decrease during exhalation). However, PPG signal is extremely susceptible to motion artifacts which masks the pulse peaks. To get a robust detection of PPG peak detection, we have implemented and compared the results of 1) bandpass filtering 2) Wavelet decomposition 3) Normalized least mean square (NLMS) adaptive filtering and 4) Recursive least square (RLS) adaptive filtering-based approaches. The PPG signals were acquired from Samsung Galaxy Active2 watch from 28 healthy subjects and simultaneous ECG recordings were acquired from Vitalpatch ECG sensor that has been placed on the chest. The PPG and ECG signals are continuously recorded for 5-7 days, except for the time when the watch was taken off to be charged. The PPG signal is affected by motion artifact induced by a wide range of activities.
          The evaluation of true positive detection is based on the following assumptions:
          1. There is only one true PPG peak between two R-peaks of ECG data.
          2. If the peak detection algorithm detects more than one PPG peaks in between two R-R intervals, the true peak is identified from R-R interval from preceding ECG cycles. The rest of the peaks are labelled as false positive detection.
          The benchmarks of performance are the rate of true positive detections with respect to ECG. The aims for the final project are: Aim 1) reporting the TP rate for all 4 preprocessing techniques for 28 subjects, Aim 2) Lower the false positives in detected PPG peaks, i.e., increase TP rate(PPG) while maintaining a high TP rate (at least 70%) with respect to ECG in 1 subject. The results as of now show that the simplest approach, i.e., bandpass filtering based approach has the best performance with an average TP rate of 53% and TP rate(PPG) of 86%. The reduction of false positive detections using outlier elimination approach did not however work as expected.
          It resulted in an increase in TP rate(PPG) in 2 out of 4 cases but reduced the TP with respect to ECG in all cases. Interestingly, if we modified the peak detection to remove cubing of segments and select appropriate threshold to select outliers, it is possible to get an increase of TP to 62%. So, we have succeeded in fulfilling both the aims of the project.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/a4m3uw6o1bbutbc/Final%20Project%20Slide%20deck%20vf.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/mlvuxj67bizb3rs/Transcript%20vf.pdf?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Transcript
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading5">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse5" aria-expanded="true" aria-controls="collapse5">
        <h6>5. Arrhythmia Detection using Electrocardiogram,
        <span class="text-muted ml-2">by Rithu Varshini Annadurai</span>
        </h6>
      </button>
    </h2>
    <div id="collapse5" class="accordion-collapse collapse" aria-labelledby="heading5" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> Arrhythmia detection using the Electrocardiogram(ECG) data is performed
                  through training machine learning models like Logistic Regression and a custom
                  made Deep learning network.Arrhythmia is an abnormality in heartbeat.This is
                  diagnosed by readings taken from EKG,event monitor ,echocardiogram and
                  implantable loop recorder.The data used for this project is from MIT-BIH
                  arrhythmia database.There are 109446 samples with a sampling frequency of
                  125 Hz, also five categories of classes are considered.The classes under the
                  study include, i)Normal beat ii) Supraventricular premature beat, iii)Premature
                  ventricular contraction, iv)Fusion of ventricular and normal beat, v)Unclassifiable
                  beat.First the signal is preprocessed to normalize data and then logistic
                  regression model is applied on the data,as the data is imbalanced, accuracy
                  metric was not able to provide accurate results.Adding nonlinearities to the
                  output of logistic regression,an accuracy of 91% was achievable.After that a
                  custom made neural network was used to achieve a test accuracy of 95.2% with
                  a AUC score( measures the total area underneath the ROC curve) of 0.99. After
                  completion of the model, testing is done on the unseen data in order to quantify
                  the amount of generalization of the model on the data. The accuracy obtained
                  was the same.Also the time consumed for the diagnosis is only seconds.Hence,
                  this simple machine learning method allows a fast retraining of the classifier if
                  new ECG data become available.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/60x7zlmfx9v09tm/BSP%20Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/oob1fkh1hihs2jo/BSP%20Final%20Presentation.mov?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading6">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse6" aria-expanded="true" aria-controls="collapse6">
        <h6>6. Predicting music induced emotional responses,
        <span class="text-muted ml-2">by Yvette Espinoza</span>
        </h6>
      </button>
    </h2>
    <div id="collapse6" class="accordion-collapse collapse" aria-labelledby="heading6" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> Music is known to evoke a range of emotional responses, and thus it can be
                  used for some forms of therapy. In music therapy, the music is chosen to
                  evoke a desired emotion or response, but determining which pieces to play
                  can be challenging, requiring information on both the music and the
                  individual. This project aimed to use a combination of the music’s acoustic
                  properties and EEG measurements to predict music induced emotional
                  responses. Due to time constraints the audio feature extraction was omitted,
                  instead using 2 predefined emotions: ‘sad’ or ‘happy. The participants in the
                  dataset were first presented with different music, labeled with the emotion,
                  then questioned on their emotions. The measured EEG data was
                  preprocessed, and PCA was used to reduce the data and create a classifier to
                  predict the emotional response. The resulting classifier performed poorly,
                  though that was expected because the acoustic features of the music were
                  not included with the EEG data when creating the classifier.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/a577ri35nxjs251/BME511_Project.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/dvp8mdrv5uduqsp/Espinoza_Project.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading7">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse7" aria-expanded="true" aria-controls="collapse7">
        <h6>7. Musical pitch and EEG signals,
        <span class="text-muted ml-2">by Trey Bosfield</span>
        </h6>
      </button>
    </h2>
    <div id="collapse7" class="accordion-collapse collapse" aria-labelledby="heading7" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> Perfect pitch is the rare ability to recognize a note without a reference; relative pitch is the ability to recognize the difference between two or more pitches. Musicians throughout their lifetime
          (those with and without perfect pitch) train their relative pitch, as it helps with harmony, melody,
          and so many more fundamental and advanced concepts that makes music sound the way it
          does. The part of the brain that is responsible for understanding and processing pitch is the
          auditory cortex. The question arose on whether or not it’s possible to compare musicians'
          relative pitch against each other through the use of EEG signals. Experimental eeg raw data
          was taken from Goldman et al. paper on improvisation effect on categorizing musical structures.
          The EEG data of two random subjects in the experiment were preprocessed and compared.
          The results showed that while it was possible to visualize which subject had the better relative
          pitch, it was determined that a classification approach (like AUC or PCA) would be better to
          more easily visualize how good someone’s relative pitch is using EEG data.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/wyn73l7098mbc9g/Bme%20511%20prsentation%20pdf%20slides.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/s69yy5vdxi9clrz/BME%20511%20final%20project.m4v?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading8">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse8" aria-expanded="true" aria-controls="collapse8">
        <h6>8. Synthetic Segmented Virtual Head Model Generation Using Generative Adversarial Network (GAN),
        <span class="text-muted ml-2">by Nahian Ibn Hasan</span>
        </h6>
      </button>
    </h2>
    <div id="collapse8" class="accordion-collapse collapse" aria-labelledby="heading8" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> The structural information of the human brain assists in different research such as Transcranial Magnetic Stimulation (TMS), Transcranial Direct Current Stimulation (tDCS), brain tumor detection, uncertainty quantification analysis, etc. However, MRI images of less than 3T resolution are of little use since the tissue boundaries become uncertain in the brain. On the other hand, acquiring a substantial number of higher resolution images (3T, 5T, 7T) is significantly expensive. Hence, an expanded database is often necessary for population-based studies, which is often quite impossible to gather from a single machine, environment, or race of people. Therefore, we aim to develop a workflow to generate synthetic segmented MRI images, which will help in the population-based analysis and machine learning algorithms. Since generating "3D synthetic human head models" is computationally expensive, we aim to work with a single slice of MRI scans. The virtual head models (for ground-truth MRI scans), generated from SimNIBS/Fresurfer, are voxelated to a uniform grid space. Next, we utilize the Generative Adversarial Network (StyleGAN) to produce synthetic segmented MRI slices using over 800 MRI data from Human Connectome Project. The Frechet Inception Distance (FID) score between 5000 generated images and real dataset resembles realistic synthetic data.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/r57jbpjjejsz07f/Final_Project_Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/0n85og8y100p4w7/Final_Project_Presentation_Nahian_small.mov?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading9">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse9" aria-expanded="true" aria-controls="collapse9">
        <h6>9. Bayesian Decoding of Hippocampal Cell Assemblies Predicts Location Specific Neural Mapping,
        <span class="text-muted ml-2">by Hammad Khan</span>
        </h6>
      </button>
    </h2>
    <div id="collapse9" class="accordion-collapse collapse" aria-labelledby="heading9" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>It is well established that the mammalian hippocampus is chiefly responsible for the consolidation of short-term memories and memories associated with spatial navigation. The CA1 region of the hippocampus contains pyramidal neurons that fire in relation to an animal’s position in space. These neurons, termed place cells, fire consistently throughout many behavioral trials. At the population level these neurons capture the spatial field of an environment and can remain stable for longs periods of time. Hence, the neural dynamics of place cells become predictive and reflect synaptic potentiation as a function of behavior. Given the predictive nature of place cell firing, can future locations of the animal be predict based on neural data alone? Here, I train a naïve Bayesian decoder to probabilistically predict an animal’s location in space based on neural data from identified place cells. By developing a multi-step preprocessing pipeline, place cells can be identified from neural recordings of a mouse as it navigates an environment. The Bayesian decoder classified and predicted the location of the animal 60-70% of the time across trials. Although the inherent stochasticity of neural firing rate potentially skewed decoder performance, the comparison of place field prediction was comparable to ground-truth data. Taken together, the dynamic behavior of hippocampal neurons can be captured and predicted using a naïve Bayesian decoder.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/0vnw9w6d1q137vy/BME511Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/u6cdpt0a1tbotpi/PresentationBME511.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading10">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse10" aria-expanded="true" aria-controls="collapse10">
        <h6>10. Common spatial pattern based Motor imagery classification,
        <span class="text-muted ml-2">by Amith Kashyap</span>
        </h6>
      </button>
    </h2>
    <div id="collapse10" class="accordion-collapse collapse" aria-labelledby="heading10" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> The aim of this project is to understand and decode the EEG signals responsible for the motion of hands and feet in a human subjects. One method of doing so is the use of motor imagery.
          Patterns in brain activity while performing motor imagery are observed in different frequency
          bands for different subjects. This necessitates a subject specific classification scheme. In this
          study we use the method of common spatial patterns(CSP) to extract features from 8 different
          frequency bands(overlapping 4 Hz bands between 4 and 36 Hz) that separates the 8 class motor
          imagery dataset recorded by Schalk G Et Al. Seven different binary classifiers are train to
          differentiate and classify the 8 class problem. The features for each of the 7 classifiers are hand
          crafted for the specific classes that are being classified. The logarithm of the variance of the
          top and bottom 4 sources of all the 8 frequency bands are fed to the classifier for classification.
          The results are quantified by computing the accuracy, precision score, recall score and the f1
          score metrics. The data of each subject was split into train test split and an average accuracy
          of 97.61%. The study also briefly touches on the pitfalls of applying deep learning algorithms
          on motor imagery based dataset.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/exrvwrwozguxlno/BME_511_Final_Presentation_Amith_Kashyap.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/6ve4a4xn18uzsoj/Final_BME_511_presentation.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading11">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse11" aria-expanded="true" aria-controls="collapse11">
        <h6>11. Sleep Stage Prediction via EEG Periodogram Frequency Band Energy Classification,
        <span class="text-muted ml-2">by Chris Kannmacher</span>
        </h6>
      </button>
    </h2>
    <div id="collapse11" class="accordion-collapse collapse" aria-labelledby="heading11" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>An important measure in determining the quality of one’s sleep is determining the stages of sleep one is experiencing in a given night. Currently, sleep scoring is performed by experts on EEG data from the subject during sleep. However, this can cause problems because the results can differ from scorer to scorer. Therefore, there is a need to create a consistent classification model to determine the sleep stages in subjects from EEG data. This project used 6 healthy subjects from the CAP sleep database and created a decision-tree classifier that compared the energy of different frequency bands within the EEG signal. This model differs from others because this model uses the spectral information from the periodogram instead of analyzing just the Fourier transform of the EEG signals. This was done because this project did not assume stationarity in the EEG signal, which should be appropriate because the EEG signal is changing as the subject goes through the sleep cycles. In the end, this model achieved a training accuracy of 65% and testing accuracy of 55% in classifying 6 classes of sleep: awake, stages I – IV, and REM. Due to issues with the consistency of the dataset, preprocessing, and selecting classifiers, this project had its share of difficulties. However, an accuracy of 55% for distinguishing 6 different classes is still significant. Future work includes utilizing more data, perfecting the preprocessing of the data, and experimenting with both the periodogram and Fourier transform to increase accuracy.

          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/oejl5ezblehsbsg/Kannmacher_Presentation_Slides.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/lqxrbcp83r64m5r/Kannmacher_Presentation_Final.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading12">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse12" aria-expanded="true" aria-controls="collapse12">
        <h6>12. A deep learning framework to remove endogenic artifacts from EEG signals,
        <span class="text-muted ml-2">by Yuqing Huang</span>
        </h6>
      </button>
    </h2>
    <div id="collapse12" class="accordion-collapse collapse" aria-labelledby="heading12" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> Since endogenic artifacts, such as electrooculogram (EOG) and electromyography (EMG), always contaminate EEG signal, a deep learning framework is proposed to separate EEG signal and endogenic artifacts in the embedding space and reconstruct the denoised signal later. The framework is named DeepSeparator. DeepSeparator employs an encoder to extract and amplify the features in the raw EEG, a module called decomposer to extract the trend, detect and suppress artifact and a decoder to reconstruct the denoised signal. In this project, a set of pure EEG is set as ground truth. Then mix this set of signal with EOG and EMG signals as input. After the process of DeepSeparator, comparing the output with ground truth to show how well the deep learning framework works. Compared with traditional methods, DeepSeparator does not rely on any prior assumptions, and can extract clean EEG.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/qqy2z9ieu6oynnz/final.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/cn48vfuknqbgwmc/YuqingHuangFinalPre.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading13">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse13" aria-expanded="true" aria-controls="collapse13">
        <h6>13. Reverse Engineering Single Cell RNA-seq Analysis,
        <span class="text-muted ml-2">by Jonathan Huang</span>
        </h6>
      </button>
    </h2>
    <div id="collapse13" class="accordion-collapse collapse" aria-labelledby="heading13" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Genomic data provides valuable insights into the development and characterization of biological and disease processes with DNA sequencing allowing the description of phenotype at the building block level and RNA sequencing giving a window to observe processes in action. Over the last decade, it has been clear that there is missing information lost in tissue heterogeneity that fails to be captured in bulk-sequencing. With the commercialization of single-cell sequencing, there has been an impressive rise in investigators exploring the subpopulations elucidated by the technology. However, the complexity introduced by this granularity requires significantly more resource intensive computational methods. Creation of these methods requires more specialization and as a result, there can be gaps in knowledge between the processing and interpretation of the large datasets. As such, although there are existing methods to process and analyze this type of data, here I seek to reverse engineer these methods to come to a better understanding of the analysis pipelines. 
          494 cells down sampled from a single-cell RNA sequencing data from the caudate will be used through this analysis.
          First a filtering step is necessary due to the technical artifacts present in the sparse data. Next, dimension reduction is required to interpret scRNA data due to the inherent large number of features. After dimension reduction, a shared neighbor algorithm will be used to map the cell clusters.
          Results compared with Seurat show that these steps successfully replicated the traditional scRNA-seq pipeline.

          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/ago0he1a6vpckp3/FProjPresentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/aa6kbmuqn9nmwd8/FProjPresentation.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading14">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse14" aria-expanded="true" aria-controls="collapse14">
        <h6>14. Mouse Paw Sensation and Interpretation: Responses in S1 and M1 Cortex,
        <span class="text-muted ml-2">by Myriam Hrosz</span>
        </h6>
      </button>
    </h2>
    <div id="collapse14" class="accordion-collapse collapse" aria-labelledby="heading14" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> Animals respond to environmental changes through their perceived notion of the world. Thus, understanding how different regions of the brain communicate to effectively adapt to environmental factors is important. Genetically modified mice (GCaMP6s x CamKII-tTa) were placed on a wheel with three different textures, 40 minutes of behavioral and neural data were recorded. The initial hypothesis was that mice would prefer a smoother surface due to less neurons firing in S1. This in turn would lead to less firing in M1. After processing in DeepLabCut and Suite2p, respectively, a correlation between firing rates and different sensory stimuli was noticed. Mice had a stronger preference for 310-grit sandpaper due to smaller firing rates in S1 cortex. Goal: Determine neural preference in both M1 and S1 in relation to different sensory stimuli.

          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/tibtaant4mcnodh/Final%20Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/mc0p5omqv74m8qs/video1628527724.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading15">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse15" aria-expanded="true" aria-controls="collapse15">
        <h6>15. Feasibility of Principal Component Analysis (PCA) for Non-Real Time Detection of Abnormal Heart Rhythms (Arrhythmias),
        <span class="text-muted ml-2">by Amy Hostetler</span>
        </h6>
      </button>
    </h2>
    <div id="collapse15" class="accordion-collapse collapse" aria-labelledby="heading15" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> To analyze an electrocardiogram, ECG, of a patient to detect abnormal heart rhythms, an expert is needed to diagnose the patients. There is potential for signal processing to be done after an ECG is captured to classify any abnormal heart beats in the data. This project uses the Arrhythmia Database from MIT-BIH by George Moody and Roger Mark which was first distributed in 1980. This is a collection of 47 subjects with a combination of normal heart rhythms and arrhythmias. Moody’s WFDB conversion software was used to create readable ECG data. This project filtered these ECGs to pass the frequencies between 0.5 to 150 Hz based on recommendations from the American Heart Association published in 2007. The data was separated into sections of the ECGs with the same classifications of arrhythmias or normal heart rhythms. These were then dimensionally reduced using a short sample of the data which seemed to have the most difference between the arrhythmias and normal heart rhythm. These were further reduced using PCA to find the most variable components. The resulting criteria for finding specific classifications of arrhythmias show some promise of the application of these methods on other classifications of arrhythmias if the selection criteria between normal and the arrhythmia is more refined. With ventricular flutter wave, there is a 68% false detection of ventricular flutter with normal heart beats.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/37htc93v2ququdm/Final%20Project%20Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/yy2136849uqx10n/Final%20Project%20Presentation.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading16">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse16" aria-expanded="true" aria-controls="collapse16">
        <h6>16. Comparison between measures of Cortical Waveforms and Inter-trial Coherence (ITC) to three different gap durations in younger and middle-aged adults,
        <span class="text-muted ml-2">by Varsha Mysore Athreya</span>
        </h6>
      </button>
    </h2>
    <div id="collapse16" class="accordion-collapse collapse" aria-labelledby="heading16" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> Many individuals with normal hearing thresholds have difficulty in communication in adverse listening conditions, like in noise or in reverberation. Such difficulties have been majorly documented in older adults, and individuals exposed to noise. There are several factors that aids speech perception in noise, and one of the primary contributors is precise temporal coding of the stimulus. To study temporal coding, we are using a gap detection paradigm of tones with gap durations of 16, 31 and 64 ms in younger and older adults. I have used 31-channel EEG data from 5 younger adults (18-30 years) and 1 middle-aged adult (47 years) to elicit an auditory cortical response. The signal processing techniques used to analyze the cortical response from the raw EEG data were – (1) re-referencing to the mastoid electrodes, (2) band-pass filtering (1-40 Hz), (3) Epoching the three gap durations separately by using 3 triggers, (4) Artifact rejection to remove eye blinks and other muscle-related artifacts, (5) Averaging the three different epochs and (6) Inter-trial coherence (ITC) measures using multitaper method to elucidate the extent of phase-locking for the three gap-durations (giving us a measure of cortical synchrony). I obtained the following responses from the analysis – (1) Onset cortical response to the start of the stimulus, (2) Cortical responses to the three different gap durations, and (3) ITC measures across the three gap durations. The ITC increased with increase in the gap durations, which was not evident in the cortical response waveforms.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/pjvhfx7wmapt66u/BME%20511-%20Final%20Project%20%28Varsha%29.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/yzcksayjfb9xqnb/Varsha_BME511_FinalProject_Presentation.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading17">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse17" aria-expanded="true" aria-controls="collapse17">
        <h6>17. Motion Artifact Removal from EEG and fNIRS Data,
        <span class="text-muted ml-2">by Peter Zoss</span>
        </h6>
      </button>
    </h2>
    <div id="collapse17" class="accordion-collapse collapse" aria-labelledby="heading17" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>The analysis of EEG and fNIRS data for the removal of motion artifacts is important because of the noise they can cause to the raw neural data. To better understand and analyze the data, it is necessary to accurately remove the motion artifacts without losing important information. This is especially true for EEG and fNIRS data where eye movement is more easily detected when recording these signals. The filtering technique I use is able to remove the motion artifacts from the raw data signals and showing what the predicted motion artifact data should look like. The theoretical motion artifact data is then obtained for comparison to the predicted motion signal from the filtered data. The similarities between the two signals are high, showing the potential this technique has.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/7t13993t36hvezf/BME511_FinalPresentation_pzoss.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/4k286ltic13kvc4/BME511_FinalPresentation_pzoss.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading18">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse18" aria-expanded="true" aria-controls="collapse18">
        <h6>18. Fetal HR detection from abdominal ECG,
        <span class="text-muted ml-2">by Damen Wilson</span>
        </h6>
      </button>
    </h2>
    <div id="collapse18" class="accordion-collapse collapse" aria-labelledby="heading18" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Fetal heart rhythm arrhythmias are very dangerous, and it is crucial for a caregiver to be aware of such arrythmias for care of the mother and baby. Current solutions are not ideal for continuous monitoring and have limited use cases. By use of a NI-FECG (non-invasive fetal electrocardiogram) it is possible to separate the mother’s ECG waveforms and the fetus’s waveforms. The data set used was collected from 5 women in labor with simultaneous recording of multichannel abdominal ECG and direct inserted invasive fetal ECG (FECG) (ground truth). The main objectives of this were to separate the maternal and fetal ECGs, determine fetal R-peaks and HR, and compare these R-peak detections with the FECG’s R-peaks. First, the data was bandpass filtered and then the first principal component from PCA was used to isolate a clean maternal ECG, and ICA’s first component was used an initial estimate of NI-FECG. Next these two signals were separated using the orthogonality principle. Finally, after wavelet denoising, and 18-35Hz filtering, R-peak detection was performed on the NI-FECG estimate. The analysis pipeline had an average of 81.49% accuracy for R-peaks compared to the FECG recording, 24.00% miss rate, and a 18.35% false alarm rate in detecting false R-peaks. In conclusion, a large proportion of the R-peaks coming from the fetus were detected, but there was a sizeable portion of false and missed peaks as well. Further analysis incorporating improved peak detection and source separation could make this a viable tool in noninvasive fetal ECG monitoring. 
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/7hbas6tkb3ahgqf/Final%20Presentation%20-%20Fetal%20HR%20Detection%20from%20Abdominal%20ECG%20Draft.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/0ahktb7u1bgsfsu/Final%20Presentation%20-%20Fetal%20HR%20Detection%20from%20Abdominal%20ECG%20Draft.pptx?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading19">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse19" aria-expanded="true" aria-controls="collapse19">
        <h6>19. Python Analysis of ECG Signals,
        <span class="text-muted ml-2">by Abigail Van Wormer</span>
        </h6>
      </button>
    </h2>
    <div id="collapse19" class="accordion-collapse collapse" aria-labelledby="heading19" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>About 1 in every 4 Americans will die from heart disease, making it the leading cause of death in the United States. Electrocardiography, or ECG, signaling is a way to capture information about the heart using electrical signals. ECGs are used to diagnose and track a patient’s heart health. In order to help physicians diagnose heart disease faster and more accurately, a python analysis of ECG signals was performed. One control dataset and one noisy dataset were provided from Paul van Gent for this project. The analysis was performed using the control dataset and included extracting the following information from the raw signal: the R-peaks and the interval in between them, the moving heart rate average, the average heart rate, and the heart rate variability features. Next, a filtering function was created to clean up the noisy ECG signal. However, the signal had prior filtering done by the device it was collected with, so the noisy signal was used to find the previously listed features. Although the filtering function was not used with the noisy dataset, it can be used in the future. Comparing the two datasets, it was found that the control data that was collected from a laying down position had much lower values than the noisy data collected while the person was moving around. This makes sense due to the nature of how the data was collected. Using the code written, physicians have the capability to use this analysis to deliver quick diagnoses of heart disease to patients.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/wqtzj8jq31pd4iw/Van%20Wormer%20Final%20Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/dn4i6whkwiuf5au/VanWormer_Presentation.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading20">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse20" aria-expanded="true" aria-controls="collapse20">
        <h6>20. MHD Effect: Isolating ECG Signal from ECG recording taken during MRI Scan,
        <span class="text-muted ml-2">by Robert Thurston</span>
        </h6>
      </button>
    </h2>
    <div id="collapse20" class="accordion-collapse collapse" aria-labelledby="heading20" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>When recording a patient’s ECG signal during MRI exams, the interaction between the ions in the blood and the magnetic field generated from the MRI scanner create an MHD signal. This generated MHD signal then superimposes itself with the ECG signal and therefore prevents the detection of key components of the ECG signal such as the QRS complex. Therefore, the objective of this project was to separate the MHD signal from the ECG signal and then isolate the QRS complex. These objectives will be accomplished using signal processing techniques such as filtering via a bandpass filter, cross correlation, wavelet reconstruction, and peak detection.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/kw1vzl46emjk4te/final%20presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/wauz1oddv4q05nj/final%20presentation.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>


  <div class="accordion-item">
    <h2 class="accordion-header" id="heading31">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse31" aria-expanded="true" aria-controls="collapse31">
        <h6>21. MATLAB based ECG Signal Processing and Analysis,
        <span class="text-muted ml-2">by Shixing Gu</span>
        </h6>
      </button>
    </h2>
    <div id="collapse31" class="accordion-collapse collapse" aria-labelledby="heading31" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Heart disease endangers human health and even life all the time. Therefore, the
            research on Electrocardiogram ECG signal automatic analysis system has high
            clinical value. The actually detected ECG signal is easily affected by various types of
            interference signals, which further affects the analysis and processing of signals. This
            study uses MATLAB software to proces s and analyze No.109 ECG data in MIT BIH
            database, so as to reduce noise interference. In the process of analysis, EMG
            interference and baseline drift noise are selected as the processing objects, and low pass
            filter and zero phase filter are designed to p rocess them respectively. The results show
            that after the noise reduction of the two designed filters, the EMG interference and
            baseline drift in ECG have been significantly improved, and the expected effect has
            been achieved. If the noise reduction technology is applied to clinical instruments,
            clinical researchers will be able to judge specific diseases more accurately and will not
            delay the diagnosis and treatment process of patients. Therefore, ECG preprocessing is
            a very important part in medicin e, and this technology can also be combined with
            machine learning in the future, so as to work more efficiently.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/9em8xj3n2pya5eq/MATLAB%20based%20ECG%20Signal%20Processing%20and%20Analysis.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/ib59zjwkumu2cmz/video-343c87dc-c403-4439-b085-9f4e904c886a.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>


  <div class="accordion-item">
    <h2 class="accordion-header" id="heading22">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse22" aria-expanded="true" aria-controls="collapse22">
        <h6>22. Identifying and Classifying Motor Imagined Movements,
        <span class="text-muted ml-2">by Ankit Shaw</span>
        </h6>
      </button>
    </h2>
    <div id="collapse22" class="accordion-collapse collapse" aria-labelledby="heading22" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> A person suppresses mu rhythms, occurring at 8-12 hz, when he or she
            performs a motor action or even when he or she visualizes performing a
            motor action. By measuring the amount of mu activity at different locations
            on the motor cortex, we can determine which limb the subject is moving. To
            analyze the mu activity and classify left and right hand trials, the data used
            in this project comes from a 59 channel EEG device sampled at 100 Hz.
            Power Spectral Density plots of the C3,Cz, and C4 channels revealed
            interesting findings that there is suppression of mu activity in right hand
            trials in channel C3 and in left hand trials in channel C4. Furthermore, a
            popular algorithm in BCI motor research - Common Spatial Pattern (CSP)
            was applied for maximizing variance for the class of right hand trials and at
            the same time minimizing variance for left hand trials and vice versa. The
            differentiation between the classes were much clearer using this approach
            which was further tested by Machine Learning using the classifier called
            Linear Discriminant Analysis (LDA). The decision boundaries were
            observed in test and training data sets. The Confusion matrix revealed to
            have 91% accuracy in separating left and right imagined trials. This
            encouraging result can be useful for design of BCI devices and applications
            for Paralyzed patients who don't have motor control abilities.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/uxfvk7wosrllt6r/BME_511_Final_Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/sfoil9qf5bbwq47/BME511_Ankit_Final.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading23">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse23" aria-expanded="true" aria-controls="collapse23">
        <h6>23. Brain Computer Interface Using EEG Data to distinguish Between Different Motor Imagery Tasks,
        <span class="text-muted ml-2">by Sam Senneka</span>
        </h6>
      </button>
    </h2>
    <div id="collapse23" class="accordion-collapse collapse" aria-labelledby="heading23" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Brain computer interfaces are a new technology in Biomedical Engineering with many potential uses. The dataset from “A large electroencephelographic motor imagery dataset for electroencephalographic brain computer interfaces” by Murat et. Al. This dataset contained 60000 mental imagery tasks across 75 experiments, 13 patients, and 4 different BCI paradigms. I only used the data for one BCI paradigm in which patients completed motor imagery tasks of closing their left hand, right hand, or remaining passive. The main objectives of this project were to develop a BCI from this EEG data and determine which motor imagery task was being performed. I then reduced the number of channels used to train the neural network in my BCI. The data was processed by removing the reference electrodes, filtering the data, removing DC fluctuation, event extraction and finally removal of events based on noise in the trial. I first trained the BCI off the standard deviation of a single trial from the averaged trials for each motor imagery task. This network resulted in an accuracy of about 39.29% with 19 channels used, however after removing 4 channels the accuracy increased to 42.03% due to similarities between the averaged trials of the channels removed. I also trained the network on the first 3 principal components of the data which resulted in an accuracy of 42.30% for both 19 channels and 15 channels. This is very promising for both methods as it shows fewer EEG channels can be used without hindering the performance of the BCI.

          <div class="collapse d-flex justify-content-between mt-4">
            <a href="#" class="btn btn-outline-secondary btn-sm ml-2 mb-2 disabled" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/mps9uqfi80afxjl/BME%20511%20Final%20Presentation.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading24">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse24" aria-expanded="true" aria-controls="collapse24">
        <h6>24. Classification of sEMG Signals into 6 Basic Hand Movements,
        <span class="text-muted ml-2">by Priyanka Raja</span>
        </h6>
      </button>
    </h2>
    <div id="collapse24" class="accordion-collapse collapse" aria-labelledby="heading24" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong> Surface electromyography (sEMG) is a non-invasive tool used to measure the electrical activity in
          muscles by way of skin electrodes. These bioelectric signals are used in a variety of applications, which
          include prosthetics, neuromuscular rehabilitation and clinical diagnosis, requiring quick and accurate
          identification of the intended movement. The aim of this project was to implement an algorithm to
          accurately classify sEMG signals into 6 basic hand grasps which include (1) Spherical: for holding
          spherical objects (2) Tip: for holding small objects (3) Palmar: for grasping with the palm facing the
          object (4) Lateral: for holding thin, flat objects (5) Cylindrical: for holding cylindrical objects and (6)
          Hook: for supporting a heavy load. The sEMG datasets used for training and testing the classifier were
          obtained from the UCI Repository of Machine Learning Databases. The signals were segmented into
          200ms long windows, with a window increment of 50ms and a mix of time domain and frequency
          domain features were extracted from each segment. Principal Component Analysis was used to reduce
          the dimension of the feature vector, with the number of principal components chosen to give the
          maximum classification accuracy. SVM with an RBF kernel and tuned hyperparameters, C and gamma,
          were used for training and testing, and the performance of the classifier was quantified using accuracy,
          precision, recall and F1 score. The classifier had a training accuracy of 39% and a testing accuracy of 23%,
          raising the need for further study of the feature set and classifier.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/9jrtbrdkery8i4i/Project%20Presentation%20Slides.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/n2w1azvs6b6j7q3/Project%20Presentation_Final.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading25">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse25" aria-expanded="true" aria-controls="collapse25">
        <h6>25. Differential changes with age in multiscale entropy of electromyography signals from leg muscles during treadmill walking,
        <span class="text-muted ml-2">by Samuel Penrod</span>
        </h6>
      </button>
    </h2>
    <div id="collapse25" class="accordion-collapse collapse" aria-labelledby="heading25" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>This paper analyzes the electromyography signals produced from four major muscles of
            the lower extremities in two groups of people, old and young, while they walked on a treadmill
            at five different speeds. This was done using filtering, thresholding, and frequency analysis to
            test the two hypotheses that as people age their muscle activation voltages are the same and
            that their muscles fire at the same frequency. Either of these hypotheses being rejected would
            suggest that muscles in older populations don’t support their bones as much as when they were
            young leading to osteoarthritis. It was found that the muscle activation voltages for every
            combination of muscle group and walking speed except for the Vastus Lateralis at walking
            speed 5 were statistically different between the two groups as well as there being statistical
            significance for the frequency analysis at every speed for the Gastrocnemius and no statistical
            significance for the frequency analysis of the Vastus Lateralis.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="#" class="btn btn-outline-secondary btn-sm ml-2 mb-2 disabled" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/w1tarutty4o3rhb/penrod1_finalReport511.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading26">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse26" aria-expanded="true" aria-controls="collapse26">
        <h6>26. Hand Gesture Prediction via EMG Data,
        <span class="text-muted ml-2">by Ben McAteer</span>
        </h6>
      </button>
    </h2>
    <div id="collapse26" class="accordion-collapse collapse" aria-labelledby="heading26" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Electromyography (EMG) is becoming increasingly popular in gesture controls and other hands-free technology. The goal of the project was to predict four different hand gestures- Rock, Paper, Scissors, and “OK”, given EMG responses of the forearm, in as short of an amount of time as possible. The EMG data consisted of eight unmarked sensors and data was recorded for six trials of twenty seconds at a 200Hz sampling rate. The key innovation of this project involved finding the main differential characteristic to restructure the data before applying the model. The key differential characteristic was identified as the mean of the absolute value of each sensor. The data was defined by this characteristic in 1.00, 0.5, 0.25, 0.05, and 0.005 second time windows that would be used for the model. After restructuring the data, five models are applied in a 70% Train and 30% Test split. A peripheral objective became determining which type of model best predicts EMG data. The five models are: Multi-Layer Perceptron (MLP), Linear, Naïve Bayes Gaussian (NBG), K-Nearest Neighbor (KNN), and Principal Component Analysis (PCA). After applying each model, the MLP, Linear, and KNN models showed accuracies above 95% with only 1/20th of a second of data. These findings show that the four hand gestures can be predicted in a near instantaneous 1/20th of a second and therefore could allow for further gesture control devices. Future work would entail adding more gestures and testing these same models. 
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/qatoht289i7nzc6/BME%20511%20Final%20Presentation%20Ben%20McAteer.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/bup6widptvw65ed/BenMcAteer_BME511_FinalProj_GestureRecog.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>


  <div class="accordion-item">
    <h2 class="accordion-header" id="heading27">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse27" aria-expanded="true" aria-controls="collapse27">
        <h6>27. Vowel Discrimination in the Auditory and Tactile Modalities:A Time- and Frequency-domain Analysis,
        <span class="text-muted ml-2">by Juan S. Martinez</span>
        </h6>
      </button>
    </h2>
    <div id="collapse27" class="accordion-collapse collapse" aria-labelledby="heading27" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Research on tactile speech communication commonly studies participants' performance in phoneme, word,
          and phrase recognition tests; but little work has been conducted on understanding the neural bases behind
          this process, and how they may be similar or different to more common modalities for speech communication.
          This project was an exploratory study on the similarities and differences between the cortical activations
          of the tactile and auditory modalities during a two-vowel discrimination task using electroencephalography
          (EEG). One participant wore a 64-channel EEG cap while performing the task. In one condition, the vowels
          were presented auditorily via earphones. In another condition, the vowels were presented using a tactile
          display worn on the left forearm. The display presented vibrotactile patterns that corresponded to each
          vowel. These were previously learned by the participant. The EEG data was analyzed in the time-domain
          by a pre-processing stage that involved re-referencing, filtering, and removing ocular artifacts using Signal-
          Space Projection (SSP). After pre-processing, epochs were averaged for each modality and randomization
          tests were conducted for different post-stimulus time windows to determine which electrodes showed significantly different Event-Related Potentials (ERPs) between modalities. A frequency-domain analysis to study
          synchronization between electrodes was also conducted. The spectral coherence and cross-phase spectrum
          between each pair of electrodes was analyzed for both conditions. No significant differences were found on
          positive ERPs between modalities during the first 200 ms post-stimulus. Some of the frontal electrodes showed
          no significant differences between modalities beyond 200 ms post-stimulus, and coherence networks showed
          similar structures across different frequency bands.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/exgmdilujay2dfh/JSM_Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/huaksnpxbsl5mz1/JSM_Presentation.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>


  <div class="accordion-item">
    <h2 class="accordion-header" id="heading28">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse28" aria-expanded="true" aria-controls="collapse28">
        <h6>28. Principal Component Regression on FSCV Curves for Dopamine Detection,
        <span class="text-muted ml-2">by Om Kolhe</span>
        </h6>
      </button>
    </h2>
    <div id="collapse28" class="accordion-collapse collapse" aria-labelledby="heading28" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Dopamine is one of the most important neurotransmitters and is central to reward-related processes, but the exact nature of its role still remains controversial. The phasic release of dopamine is initially triggered by the receipt of a novel rewards but shifts to a cue that predicts the rewards after associative learning. Thus, is it important to study the release of dopamine and the relation to the electrical neural activity during the reward-based learning task. Fast Scan Cyclic Voltammetry (FSCV) is a method to detect dopamine with high temporal resolution while achieving high sensitivity. FSCV is conducted by measuring the redox current while sweeping the holding voltage of the electrode. The voltammetric curves obtained have peaks at the redox voltages of dopamine and the amplitude of the peak can give us the concentration of the dopamine released. However, the dopamine redox current is accompanied by currents due to pH change or redox currents of other neurotransmitters present at the electrode. In this project we will use Principal Component Regression (PCR) to extract the dopamine generated current from the FSCVs. The FSCV data was taken from Yoshimi, Kenji et al. (2015). The FSCV data was recorded from Putamen and Acumen of a monkey whiles was involved in a reward cased behavioral task. The FSCV data is first filtered and background subtracted to eliminate digitization noise and charging currents. PCR is performed using a training set generated from an in-vitro experiment. Finally, we show that we can get the dopamine current using the PCR coefficients and vectors. 

          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/ve0pqnuyn49f163/BioMedicalDSP_Final_Presentation.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/j1et4yahrrc8ife/Oral_Presentation_Om.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>

  <div class="accordion-item">
    <h2 class="accordion-header" id="heading29">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse29" aria-expanded="true" aria-controls="collapse29">
        <h6>29. Identification and prediction of epilepsy from intracranial EEG signal using DWT and machine learning models,
        <span class="text-muted ml-2">by Bilal Ahmed</span>
        </h6>
      </button>
    </h2>
    <div id="collapse29" class="accordion-collapse collapse" aria-labelledby="heading29" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Epilepsy is one of the most common neurological disorders and is characterized by unprovoked,
          recurring seizures (abnormal activity of nerve cells). It can occur to a person of any age, gender,
          race, ethnicity and takes a huge mental, psychological and financial toll on the patient. It does
          not have any fixed duration and frequency, and can occur anytime causing huge amount of anxiety
          and discomfort to the patient and their families. It can be life threatening if it occurs in dangerous
          situations like driving, swimming etc. Epilepsy is curable through medicine or surgical removal of
          seizure causing nerves in the brain. Therefore early diagnosis of epilepsy is critical for treatment
          and well-being of the patient. In some cases, it can occur even after surgical removal of epileptic
          parts of the brain. It’s effects can be suppressed using high doses of medication that can have severe
          health side effects for the patients. That’s why its identification, prediction and management is very
          important. Intracranial EEG of epileptic patients, with severe conditions, is done to identify seizure
          causing parts of the brain. Goal of this work is to identify and predict seizures from intracranial
          EEG, so that we can come up with tools that can alert patients about seizures beforehand. This
          will allow better management of situation during seizures. For example by avoiding more risky
          tasks like driving and swimming, or by limiting the use of medicine to the times when patients is
          alerted of possible seizures activity thereby reducing medicinal side effects. I have shown advantage
          of using wavelet analysis (DWT), for feature extraction and have implemented deep neural network
          models for identification and prediction of seizures. I got more than 90% accuracy for identification
          and around 80% accuracy for prediction of seizures. Prediction task can be further improved by
          making use of more data, that will be really helpful for better management of seizures.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/6lhwrlck3t6ga4n/slides_Bilal_Ahmed_final_project_BME511.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/sdfqvm5brnqioqi/Presentation%20Video_Bilal_Ahmed_final_project_BME511.mp4?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Video
            </a>
          </div>
      </div>
    </div>
  </div>


  <div class="accordion-item">
    <h2 class="accordion-header" id="heading30">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse30" aria-expanded="true" aria-controls="collapse30">
        <h6>30. Assessment of effect of Low Intensity Pulsed Ultrasound (LIPUS) on morphological and uptake changes in human umbilical vein endothelial cells (HUVECs),
        <span class="text-muted ml-2">by Claudia Benito Alston</span>
        </h6>
      </button>
    </h2>
    <div id="collapse30" class="accordion-collapse collapse" aria-labelledby="heading30" data-bs-parent="#accordionExample">
      <div class="accordion-body">
          <strong>Abstract: </strong>Subcutaneous (SC) drug delivery is the most promising method for drug delivery of biotherapeutics allowing for at home care and minimized likelihood of infection. To measure the fraction of drug that reaches the vascular system, in relation to the initial injected dose, the bioavailability is quantified. The main drawback to SC drug delivery is the low bioavailability which is often due to the inability of these more complex drugs to reach the subcutaneous blood vessels effectively whether it be owing to entanglement or size of the drug. One of the complicated aspects is getting larger biotherapeutics through the tight cell junctions in blood vessels and this report seeks to demonstrate the effect of low intensity pulsed ultrasound (LIPUS) on cell junction perturbation. By making use of Transwellplates we can grow human umbilical vein endothelial cell (HUVEC) monolayers to replicate blood vessel junctions and uptake. To assess for cell changes I measured pixel intensity, non-cell surface area, the percentage of the perimeter connecting to other cells, and assessed the granulometry differences. The hardest aspect to implement was the thresholding metric due to style of images, cell staining methods and complexity of differentiating cells in a monolayer. The final data did not reject the null hypothesis due to there being no statistical evidence that the intensity (drug uptake) or morphological changes occurred.
          <div class="collapse d-flex justify-content-between mt-4">
            <a href="https://www.dropbox.com/s/8wf1mwtezzivab3/BME511-FinalPresentation-CBA-12.15.21.pdf?dl=0" class="btn btn-outline-secondary btn-sm ml-2 mb-2" target="_blank">
              Slides
            </a>
            <a href="https://www.dropbox.com/s/pg5008lgbxpt5uj/BME511-FinalPresentation-CBA-12.15.21.pptx?dl=0" class="btn btn-outline-secondary btn-sm mr-2 mb-2" target="_blank">
              Slides with audio
            </a>
          </div>
      </div>
    </div>
  </div>

  </main>
  <footer class="pt-4 mt-4  pb-4 text-muted border-top container">
    Created using <a href="https://docs.getpelican.com/en/latest/" target="_blank">Pelican</a> and styled using <a href="https://getbootstrap.com/" target="_blank">Bootstrap 5</a>. &copy;2021 Students and instructors of BME 511. All Rights Reserved.
  </footer>


  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <!-- Option 1: Bootstrap Bundle with Popper -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>

  <script src="static/js/main.js" type="text/javascript"> </script>

</body>
